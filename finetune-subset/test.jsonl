{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def tails_t(wrap): \"\"\" Transformation for Sequence.tails", "role": "user"}, {"content": "<code>:param wrap: wrap children values with this :return: transformation \"\"\" return Transformation( 'tails', lambda sequence: [wrap(sequence[i:]) for i in range(len(sequence) + 1)], {ExecutionStrategies.PRE_COMPUTE} )</code>", "role": "assistant"}]}
{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def string_to_bytes(string): \"\"\" Returns the amount of bytes in a human readable form up to Yottabytes (YB). :param string: integer with suffix (b, k, m, g, t, p, e, z, y) :return: amount of bytes in string representation >>> string_to_bytes('1024') 1024 >>> string_to_bytes('1024k') 1048576 >>> string_to_bytes('4 G') 4294967296 >>> string_to_bytes('4.5g') 4831838208 >>> try: ... string_to_bytes('1x') ... except RuntimeError as re: ... assert 'unknown suffix' in str(re)", "role": "user"}, {"content": "<code>\"\"\" if string == '0': return 0 import re match = re.match('(\\d+\\.?\\d?)\\s?([bBkKmMgGtTpPeEzZyY])?(\\D?)', string) if not match: raise RuntimeError('\"{}\" does not match \"[integer] [suffix]\"'.format(string)) if match.group(3): raise RuntimeError('unknown suffix: \"{}\"'.format(match.group(3))) value = float(match.group(1)) if match.group(2) is None: return int(value) suffix = match.group(2).upper() extensions = ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y'] x = extensions.index(suffix) value *= 1024**x return int(value)</code>", "role": "assistant"}]}
{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def q_transform(self, qrange=qtransform.DEFAULT_QRANGE, frange=qtransform.DEFAULT_FRANGE, gps=None, search=.5, tres=\"<default>\", fres=\"<default>\", logf=False, norm='median', mismatch=qtransform.DEFAULT_MISMATCH, outseg=None, whiten=True, fduration=2, highpass=None, **asd_kw): \"\"\"Scan a `TimeSeries` using the multi-Q transform and return an interpolated high-resolution spectrogram By default, this method returns a high-resolution spectrogram in both time and frequency, which can result in a large memory footprint. If you know that you only need a subset of the output for, say, a figure, consider using ``outseg`` and the other keyword arguments to restrict the size of the returned data. Parameters ---------- qrange : `tuple` of `float`, optional `(low, high)` range of Qs to scan frange : `tuple` of `float`, optional `(log, high)` range of frequencies to scan gps : `float`, optional central time of interest for determine loudest Q-plane search : `float`, optional window around `gps` in which to find peak energies, only used if `gps` is given tres : `float`, optional desired time resolution (seconds) of output `Spectrogram`, default is `abs(outseg) / 1000.` fres : `float`, `int`, `None`, optional desired frequency resolution (Hertz) of output `Spectrogram`, or, if ``logf=True``, the number of frequency samples; give `None` to skip this step and return the original resolution, default is 0.5 Hz or 500 frequency samples logf : `bool`, optional boolean switch to enable (`True`) or disable (`False`) use of log-sampled frequencies in the output `Spectrogram`, if `True` then `fres` is interpreted as a number of frequency samples, default: `False` norm : `bool`, `str`, optional whether to normalize the returned Q-transform output, or how, default: `True` (``'median'``), other options: `False`, ``'mean'`` mismatch : `float` maximum allowed fractional mismatch between neighbouring tiles outseg : `~gwpy.segments.Segment`, optional GPS `[start, stop)` segment for output `Spectrogram`, default is the full duration of the input whiten : `bool`, `~gwpy.frequencyseries.FrequencySeries`, optional boolean switch to enable (`True`) or disable (`False`) data whitening, or an ASD `~gwpy.freqencyseries.FrequencySeries` with which to whiten the data fduration : `float`, optional duration (in seconds) of the time-domain FIR whitening filter, only used if `whiten` is not `False`, defaults to 2 seconds highpass : `float`, optional highpass corner frequency (in Hz) of the FIR whitening filter, used only if `whiten` is not `False`, default: `None` **asd_kw keyword arguments to pass to `TimeSeries.asd` to generate an ASD to use when whitening the data Returns ------- out : `~gwpy.spectrogram.Spectrogram` output `Spectrogram` of normalised Q energy See Also -------- TimeSeries.asd for documentation on acceptable `**asd_kw` TimeSeries.whiten for documentation on how the whitening is done gwpy.signal.qtransform for code and documentation on how the Q-transform is implemented Notes ----- This method will return a `Spectrogram` of dtype ``float32`` if ``norm`` is given, and ``float64`` otherwise. To optimize plot rendering with `~matplotlib.axes.Axes.pcolormesh`, the output `~gwpy.spectrogram.Spectrogram` can be given a log-sampled frequency axis by passing `logf=True` at runtime. The `fres` argument is then the number of points on the frequency axis. Note, this is incompatible with `~matplotlib.axes.Axes.imshow`. It is also highly recommended to use the `outseg` keyword argument when only a small window around a given GPS time is of interest. This will speed up this method a little, but can greatly", "role": "user"}, {"content": "<code>speed up rendering the resulting `Spectrogram` using `pcolormesh`. If you aren't going to use `pcolormesh` in the end, don't worry. Examples -------- >>> from numpy.random import normal >>> from scipy.signal import gausspulse >>> from gwpy.timeseries import TimeSeries Generate a `TimeSeries` containing Gaussian noise sampled at 4096 Hz, centred on GPS time 0, with a sine-Gaussian pulse ('glitch') at 500 Hz: >>> noise = TimeSeries(normal(loc=1, size=4096*4), sample_rate=4096, epoch=-2) >>> glitch = TimeSeries(gausspulse(noise.times.value, fc=500) * 4, sample_rate=4096) >>> data = noise + glitch Compute and plot the Q-transform of these data: >>> q = data.q_transform() >>> plot = q.plot() >>> ax = plot.gca() >>> ax.set_xlim(-.2, .2) >>> ax.set_epoch(0) >>> plot.show() \"\"\" # noqa: E501 from ..frequencyseries import FrequencySeries # condition data if whiten is True: # generate ASD dynamically window = asd_kw.pop('window', 'hann') fftlength = asd_kw.pop('fftlength', _fft_length_default(self.dt)) overlap = asd_kw.pop('overlap', None) if overlap is None and fftlength == self.duration.value: asd_kw['method'] = DEFAULT_FFT_METHOD overlap = 0 elif overlap is None: overlap = recommended_overlap(window) * fftlength whiten = self.asd(fftlength, overlap, window=window, **asd_kw) if isinstance(whiten, FrequencySeries): # apply whitening (with error on division by zero) with numpy.errstate(all='raise'): data = self.whiten(asd=whiten, fduration=fduration, highpass=highpass) else: data = self # determine search window if gps is None: search = None elif search is not None: search = Segment(gps-search/2, gps+search/2) & self.span qgram, _ = qtransform.q_scan( data, frange=frange, qrange=qrange, norm=norm, mismatch=mismatch, search=search) return qgram.interpolate( tres=tres, fres=fres, logf=logf, outseg=outseg)</code>", "role": "assistant"}]}
{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def statstable(args): \"\"\" %prog statstable *.gff Print gene statistics table. \"\"\" p = OptionParser(statstable.__doc__) opts, args = p.parse_args(args) if len(args) <", "role": "user"}, {"content": "<code>1: sys.exit(not p.print_help()) gff_files = args for metric in metrics: logging.debug(\"Parsing files in `{0}`..\".format(metric)) table = {} for x in gff_files: pf = op.basename(x).split(\".\")[0] numberfile = op.join(metric, pf + \".txt\") ar = [int(x.strip()) for x in open(numberfile)] sum = SummaryStats(ar).todict().items() keys, vals = zip(*sum) keys = [(pf, x) for x in keys] table.update(dict(zip(keys, vals))) print(tabulate(table), file=sys.stderr)</code>", "role": "assistant"}]}
{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def get_buy(self, buy_id, **params): \"\"\"https://developers.coinbase.com/api/v2#show-a-buy\"\"\" return self.api_client.get_buy(self.id,", "role": "user"}, {"content": "<code>buy_id, **params)</code>", "role": "assistant"}]}
{"messages": [{"content": "You are a code autocomplete agent. Users will input partial code snippets, and you will autocomplete the code based on the provided snippet.", "role": "system"}, {"content": "def sample_visible_from_hidden(self, hidden, n_features): \"\"\"Sample the visible units from the hidden units. This is the Negative phase of the Contrastive Divergence algorithm. :param hidden: activations of the hidden units :param n_features: number of features :return: visible probabilities \"\"\" visible_activation = tf.add( tf.matmul(hidden, tf.transpose(self.W)), self.bv_ ) if self.visible_unit_type == 'bin': vprobs = tf.nn.sigmoid(visible_activation) elif self.visible_unit_type == 'gauss': vprobs = tf.truncated_normal( (1, n_features), mean=visible_activation, stddev=self.stddev) else: vprobs = None return", "role": "user"}, {"content": "<code>vprobs</code>", "role": "assistant"}]}
